Warning: the model hallucinated some papers. We have tried to remove them, but the scores may not be accurate.<br><br>Title: <a href="https://arxiv.org/abs/2508.04224">SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry Decomposition</a><br>Authors: Jiahui Li , Shengeng Tang , Jingxuan He , Gang Huang , Zhangye Wang , Yantao Pan , Lechao Cheng<br>Score: 10<br>Reason: Gaussian Splatting 기반의 dynamic scene 재구성에서 static/dynamic 분해는 NeRF·Gaussian Splatting·novel view synthesis 및 temporal consistency 연구에 매우 직접적이고 높은 영향력을 가집니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04147">IDCNet: Guided Video Diffusion for Metric-Consistent RGBD Scene Generation with Precise Camera Control</a><br>Authors: Lijuan Liu , Wenfa Li , Dongbo Zhang , Shuo Wang , Shaohui Jiao<br>Score: 9<br>Reason: RGB-D 비디오 동시 생성 및 정확한 카메라 제어를 위한 geometry-aware diffusion/transformer 설계로, novel view synthesis·NeRF/3D reconstruction에 직접 응용 가능한 고관심 연구입니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04211">What Holds Back Open-Vocabulary Segmentation?</a><br>Authors: Josip Šarić , Ivan Martinović , Matej Kristan , Siniša Šegvić<br>Score: 9<br>Reason: open-vocabulary segmentation의 병목을 실험적으로 해석·분해하여 향후 VLM 기반 세분화와 대규모 언어-비전 사전학습 연구에 대한 깊은 통찰을 제공합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04297">MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction</a><br>Authors: Yaopeng Lou , Liao Shen , Tianqi Liu , Jiaqi Li , Zihao Huang , Huiqiang Sun , Zhiguo Cao<br>Score: 9<br>Reason: Gaussian Splatting 기반의 multi-baseline novel view synthesis는 NeRF/렌더링·3D 재구성에 직접 연관되며 ICCV 채택으로 SOTA 가능성이 높습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04508">Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds</a><br>Authors: Haodong Zhu , Changbai Li , Yangyang Ren , Zichao Feng , Xuhui Liu , Hanlin Chen , Xiantong Zhen , Baochang Zhang<br>Score: 9<br>Reason: sparse RGB views에서 카메라 포즈 추정 없이 수초 내에 surface reconstruction을 수행하는 end-to-end feedforward 기법으로, multi-view 3D reconstruction, efficiency, novel architecture 측면에서 매우 관련성이 높다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04581">Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning</a><br>Authors: Magauiya Zhussip , Dmitriy Shopkhoev , Ammar Ali , Stamatios Lefkimmiatis<br>Score: 9<br>Reason: Transformer 층 간 weight sharing을 통한 파라미터 효율화(MASA)는 novel architectures 및 모델 압축(vision transformer 포함)에 직접적으로 연관되어 중요합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04659">PixCuboid: Room Layout Estimation from Multi-view Featuremetric Alignment</a><br>Authors: Gustav Hanning , Kalle Åström , Viktor Larsson<br>Score: 9<br>Reason: multi-view feature-metric alignment 기반의 3D 실내 레이아웃 추정으로 multi-view/3D 재구성·표현학습 및 최적화 기반 방법론에 직접 연관됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04705">Occupancy Learning with Spatiotemporal Memory</a><br>Authors: Ziyang Leng , Jiawei Yang , Wenlong Yi , Bolei Zhou<br>Score: 9<br>Reason: ST-Occ는 3D occupancy와 spatiotemporal memory를 다루며, 3D perception, multi-frame aggregation 및 ICCV 채택으로 본인의 3D/representation/architectures 연구에 높은 관련성이 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04078">RLGS: Reinforcement Learning-Based Adaptive Hyperparameter Tuning for Gaussian Splatting</a><br>Authors: Zhan Li , Huangying Zhan , Changyang Li , Qingan Yan , Yi Xu<br>Score: 8<br>Reason: 본 논문은 3D Gaussian Splatting의 하이퍼파라미터 자동화에 RL을 적용하여 3D 재구성 및 렌더링 품질을 향상시키므로 3D Vision 및 training efficiency와 직접적으로 연관된다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04122">Conditional Latent Diffusion Models for Zero-Shot Instance Segmentation</a><br>Authors: Maximilian Ulmer , Wout Boerdijk , Rudolph Triebel , Maximilian Durner<br>Score: 8<br>Reason: latent diffusion을 인스턴스 분할에 적용하고 제로샷 성능 및 대규모 합성 메쉬 데이터셋으로 3D/이미지-기반 인스턴스 분리 연구(특히 diffusion 기반 segmentation 및 3D 관련 generative 모델)에 직접 연관됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04201">ViFP: A Framework for Visual False Positive Detection to Enhance Reasoning Reliability in VLMs</a><br>Authors: Ben Zhang , LuLu Yu , Lei Gao , Jing Liu , QuanJiang Guo , Hui Gao<br>Score: 8<br>Reason: VLM의 reasoning 신뢰성 향상을 위한 FP 탐지와 adaptive chain-of-thought 기법은 vision-language reasoning 및 VLM 안전성·해석성 연구에 직접적으로 기여합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04227">Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting</a><br>Authors: Yuyang Liu , Qiuhe Hong , Linlan Huang , Alexandra Gomez-Villa , Dipam Goswami , Xialei Liu , Joost van de Weijer , Yonghong Tian<br>Score: 8<br>Reason: VLM의 continual learning을 체계적으로 정리하여 cross-modal replay·regularization·parameter-efficient adaptation 등 VLM 특화 지속 학습 문제와 해결책을 포괄적으로 다룹니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04236">PIS3R: Very Large Parallax Image Stitching via Deep 3D Reconstruction</a><br>Authors: Muhua Zhu , Xinhao Jin , Chengbo Wang , Yongcong Zhang , Yifei Xue , Tie Ji , Yizhen Lao<br>Score: 8<br>Reason: 두 이미지의 대폭한 패럴랙스 문제에 대해 dense 3D reconstruction + transformer 기반 카메라 복원 및 diffusion으로 정제하는 파이프라인을 제안하여 multi-view 3D 재구성과 novel view/stitching 관련 핵심 주제와 밀접함.<br><br>Title: <a href="https://arxiv.org/abs/2508.04286">PKSS-Align: Robust Point Cloud Registration on Pre-Kendall Shape Space</a><br>Authors: Chenlei Lv , Hui Huang<br>Score: 8<br>Reason: 포인트클라우드 정합(point cloud registration)은 3D 비전 핵심 주제이며, 견고한 PKSS 기반 접근과 TVCG 출판은 실무적·이론적 가치가 큽니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04335">RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization</a><br>Authors: Yanyan Li , Ze Yang , Keisuke Tateno , Federico Tombari Liang Zhao , Gim Hee Lee<br>Score: 8<br>Reason: 3D 선형 표현과 manifold 최적화를 통해 SLAM/SfM 및 pose estimation에 직접적인 기여를 하므로 3D reconstruction 및 novel representations 관심사에 매우 관련있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04505">MonoCloth: Reconstruction and Animation of Cloth-Decoupled Human Avatars from Monocular Videos</a><br>Authors: Daisheng Jin , Ying He<br>Score: 8<br>Reason: monocular video로부터 part-based clothed human avatar reconstruction 및 cloth simulation을 결합하여 3D 재구성·애니메이션 문제를 다루어 3D vision·reconstruction·rendering 연구에 직접적이고 실용적이다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04567">Analyzing and Mitigating Object Hallucination: A Training Bias Perspective</a><br>Authors: Yifan Li , Kun Zhou , Wayne Xin Zhao , Lei Fang , Ji-Rong Wen<br>Score: 8<br>Reason: Vision-Language Models의 hallucination 문제를 훈련 데이터 편향 관점에서 분석하고, 경량화된 unlearning 기법(특히 LM head만 업데이트)을 제안하여 VLM/VLM 계열 모델의 신뢰성 향상에 직접적으로 기여합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04597">Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline</a><br>Authors: Linqing Zhao , Xiuwei Xu , Yirui Wang , Hao Wang , Wenzhao Zheng , Yansong Tang , Haibin Yan , Jiwen Lu<br>Score: 8<br>Reason: RGB-only feed-forward SLAM with Gaussian mapping 및 fast pose inference는 3D reconstruction, Gaussian Splatting, SLAM 및 real-time tracking 등 제 고우선순위 연구주제와 직접적으로 관련됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04655">X-SAM: From Segment Anything to Any Segmentation</a><br>Authors: Hao Wang , Limeng Qiao , Zequn Jie , Zhijian Huang , Chengjian Feng , Qingfang Zheng , Lin Ma , Xiangyuan Lan , Xiaodan Liang<br>Score: 8<br>Reason: SAM을 확장해 MLLM의 픽셀 수준 분할 능력을 강화하고 통합 학습 전략을 제시하여 VLM/멀티모달 및 세분화 관련 연구에 직접적인 기여를 합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04681">Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions</a><br>Authors: Liang Xu , Chengqun Yang , Zili Lin , Fei Xu , Yifan Liu , Congsheng Xu , Yiyi Zhang , Jie Qin , Xingdong Sheng , Yunhui Liu , Xin Jin , Yichao Yan , Wenjun Zeng , Xiaokang Yang<br>Score: 8<br>Reason: 대규모 에고센트릭 멀티모달 데이터셋과 행동·객체 상호작용 벤치마크는 3D/비전-언어 및 행동 예측 연구에 중요한 리소스를 제공합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04059">Beyond the Visible: Benchmarking Occlusion Perception in Multimodal Large Language Models</a><br>Authors: Zhaochen Liu , Kaiwen Gao , Shuyi Liang , Bin Xiao , Limeng Qiao , Lin Ma , Tingting Jiang<br>Score: 7<br>Reason: MLLM들의 시각적 추론 특히 occlusion perception 평가 벤치마크는 vision-language 모델의 한계 분석과 데이터셋/평가 설계에 직접적으로 관련되어 VLM 연구자에게 유익합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04182">Hacking Hallucinations of MLLMs with Causal Sufficiency and Necessity</a><br>Authors: Peizheng Guo , Jingyao Wang , Wenwen Qiang , Huijie Guo , Changwen Zheng , Jiahuan Zhou , Gang Hua<br>Score: 7<br>Reason: MLLM의 hallucination을 causal 분석으로 해결하는 RL 기반 보상 설계는 VLM의 신뢰성·응답 정합성 개선에 중요한 기여를 할 가능성이 큽니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04228">LayerT2V: Interactive Multi-Object Trajectory Layering for Video Generation</a><br>Authors: Kangrui Cen , Baixuan Zhao , Yi Xin , Siqi Luo , Guangtao Zhai , Xiaohong Liu<br>Score: 7<br>Reason: Text-to-Video에서 multi-object trajectory 제어는 비디오 합성·모션 제어·layered generation 설계 등 비전 생성 모델과 제어 가능한 생성 연구에 관련성이 높습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04485">QuantVSR: Low-Bit Post-Training Quantization for Real-World Video Super-Resolution</a><br>Authors: Bowen Chai , Zheng Chen , Libo Zhu , Wenbo Li , Yong Guo , Yulun Zhang<br>Score: 7<br>Reason: video diffusion models의 low-bit post-training quantization을 다루며, diffusion 기반 VSR의 효율화(quantization, temporal-aware) 및 실무 배포 관련 연구로 본인의 diffusion/efficiency 관심사에 직접적 관련이 있다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04677">ANPrompt: Anti-noise Prompt Tuning for Vision-Language Models</a><br>Authors: Yansheng Gao , Yufei Zheng , Jinghan Qu , Zixi Zhu , Yukuan Zhang , Shengsheng Wang<br>Score: 7<br>Reason: VLM 프롬프트 튜닝의 견고성 향상을 다루어 Vision-Language 모델의 일반화 및 견고성 연구에 직접적으로 기여합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04702">BEVCon: Advancing Bird's Eye View Perception with Contrastive Learning</a><br>Authors: Ziyang Leng , Jiawei Yang , Zhicheng Ren , Bolei Zhou<br>Score: 7<br>Reason: BEVCon은 BEV 표현 학습을 위한 contrastive learning으로 3D/자동주행 및 representation learning에 직접적으로 기여하여 본인의 관심사와 밀접합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04050">DOMR: Establishing Cross-View Segmentation via Dense Object Matching</a><br>Authors: Jitong Liao , Yulu Gao , Shaofei Huang , Jialin Gao , Jie Lei , Ronghua Liang , Si Liu<br>Score: 6<br>Reason: 크로스-뷰 객체 매칭 및 dense correspondence는 multi-view 이해와 일부 3D/pose 관련 응용에 유의미하며, 객체 관계 모델링과 mask refinement는 CV 및 representation learning 관심사와 연관됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04136">UniFGVC: Universal Training-Free Few-Shot Fine-Grained Vision Classification via Attribute-Aware Multimodal Retrieval</a><br>Authors: Hongyu Guo , Kuan Zhu , Xiangzhao Hao , Haiyun Guo , Ming Tang , Jinqiao Wang<br>Score: 6<br>Reason: MLLM과 멀티모달 검색을 이용한 training-free few-shot FGVC로 VLM·multimodal retrieval 및 표현 활용 관점에서 흥미롭고 CLIP-like 방법과 직접 관련됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04161">Audio-Assisted Face Video Restoration with Temporal and Identity Complementary Learning</a><br>Authors: Yuqin Cao , Yixuan Gao , Wei Sun , Xiaohong Liu , Yulun Zhang , Xiongkuo Min<br>Score: 6<br>Reason: 오디오-비디오를 이용한 얼굴 비디오 복원으로 멀티모달 보조 신호 활용, temporal 및 identity 학습은 비디오 복원·멀티모달 표현 학습에 관련됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04175">AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization</a><br>Authors: Jingyi Liao , Yongyi Su , Rong-Cheng Tu , Zhao Jin , Wenhao Sun , Yiting Li , Dacheng Tao , Xun Xu , Xulei Yang<br>Score: 6<br>Reason: MLLM을 산업용 anomaly detection에 적응시키는 방법론으로, 멀티스테이지 추론과 reward 설계는 VLM/representation 적응 및 효율적 fine-tuning에 시사점이 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04181">Deeper Inside Deep ViT</a><br>Authors: Sungrae Hong<br>Score: 6<br>Reason: 대규모 ViT 아키텍처(Deeper ViT)와 안정화/이미지 생성 실험은 novel architectures 및 비전 트랜스포머 확장성 연구와 직접적으로 관련됩니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04197">Gather and Trace: Rethinking Video TextVQA from an Instance-oriented Perspective</a><br>Authors: Yan Zhang , Gangyan Zeng , Daiqing Wu , Huawen Shen , Binbin Li , Yu Zhou , Can Ma , Xiaojun Bi<br>Score: 6<br>Reason: 이 논문은 video text VQA에서 instance-oriented representation과 spatio-temporal tracing을 통해 효율성과 정확도를 개선하여 비전-언어 멀티모달 추론과 시퀀스 기반 비전 모델 설계에 시사점을 제공합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04260">Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark</a><br>Authors: Xiao Wang , Ziwen Wang , Wentao Wu , Anjie Wang , Jiashu Wu , Yantao Pan , Chenglong Li<br>Score: 6<br>Reason: SAM 기반의 vehicle part segmentation과 대규모 VehicleSeg10K 데이터셋 제안은 비전 모델·시맨틱 분할·대형 모델 응용 측면에서 유의미하며 VLM/segmentation 관심과 연관됨.<br><br>Title: <a href="https://arxiv.org/abs/2508.04280">Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success</a><br>Authors: George Bredis , Stanislav Dereka , Viacheslav Sinii , Ruslan Rakhimov , Daniil Gavrilov<br>Score: 6<br>Reason: VLM에 RL을 결합해 시뮬레이터에서 학습한 정책이 실제 이미지 기반 벤치마크로 일반화된다는 점은 vision-language 학습과 에이전트 행동 학습에 유의미합니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04366">RotatedMVPS: Multi-view Photometric Stereo with Rotated Natural Light</a><br>Authors: Songyun Yang , Yufei Han , Jilong Zhang , Kongming Liang , Peng Yu , Zhaowei Qu , Heng Guo<br>Score: 6<br>Reason: Multiview photometric stereo에서 natural illumination을 다루며 shape·reflectance 복원으로 3D 복원 및 inverse rendering 관심사와 직접적 연관이 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04427">Decoding the Multimodal Maze: A Systematic Review on the Adoption of Explainability in Multimodal Attention-based Models</a><br>Authors: Md Raisul Kibria , Sébastien Lafond , Janan Arslan<br>Score: 6<br>Reason: 이 논문은 multimodal attention 기반 모델의 explainability를 체계적으로 정리하여 VLM의 해석가능성 연구에 도움이 됩니다; 그러나 주로 리뷰 논문이라 새 아키텍처나 3D/NeRF 관련 기여는 적습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04472">Zero-Residual Concept Erasure via Progressive Alignment in Text-to-Image Model</a><br>Authors: Hongxu Chen , Zhen Wang , Taoran Mei , Lin Li , Bowei Zhu , Runshi Li , Long Chen<br>Score: 6<br>Reason: 이 논문은 text-to-image generative 모델의 concept erasure에 대한 closed-form 최적화와 layer-wise 업데이트 전략을 제안하여 generative model의 제어와 보존(quality) 측면에서 실용적이며, VLM/representation 조정 관점에서 유용할 수 있다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04539">TopKD: Top-scaled Knowledge Distillation</a><br>Authors: Qi Wang , Jinjia Zhou<br>Score: 6<br>Reason: logit 기반 Knowledge Distillation과 ViT 대상 성능 향상은 Novel Architectures·Training Efficiency 및 모델 압축 관점에서 유용하며, 비전 모델 경량화·전이학습 관련 연구에 실무적 적용성이 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04576">ConfProBench: A Confidence Evaluation Benchmark for MLLM-Based Process Judges</a><br>Authors: Yue Zhou , Yi Chang , Yuan Wu<br>Score: 6<br>Reason: MLLM의 reasoning 및 confidence 평가 벤치마크는 VLM/MLLM 신뢰성 연구에 유용하며, multimodal reasoning calibration 관련 연구에 관심이 있는 경우 참고 가치가 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04604">TURA: Tool-Augmented Unified Retrieval Agent for AI Search</a><br>Authors: Zhejun Zhao , Yuehu Dong , Alley Liu , Lixue Zheng , Pingsheng Liu , Dongdong Shen , Long Xia , Jiashu Zhao , Dawei Yin<br>Score: 6<br>Reason: Tool-augmented retrieval과 agentic framework는 retrieval/RAG 한계를 극복하는 실용적 아키텍처로, VLM과 검색 연동 연구에 응용 가능성이 있어 관련성이 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04605">Multitask Learning with Stochastic Interpolants</a><br>Authors: Hugo Negrel , Florentin Coeurdoux , Michael S. Albergo , Eric Vanden-Eijnden<br>Score: 6<br>Reason: 이 논문은 diffusion/flow 계열의 generative 모델을 일반화하고 multi-task/conditional generation과 posterior sampling에 적용하여 representation learning과 효율적 생성(inference) 측면에서 흥미로운 아이디어를 제시합니다. CV/3D 직접 응용은 적지만 score-based generative modeling과 멀티태스크 operator 설계가 diffusion 관련 연구에 영감이 될 수 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04663">HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models</a><br>Authors: Young D. Kwon , Rui Li , Sijia Li , Da Li , Sourav Bhattacharya , Stylianos I. Venieris<br>Score: 6<br>Reason: 대규모 diffusion 모델의 구조적 압축 및 블록별 민감도 분석은 3D/이미지 생성 및 효율화(특히 diffusion 기반 3D 합성)에 응용될 여지가 있습니다.<br><br>Title: <a href="https://arxiv.org/abs/2508.04682">TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction</a><br>Authors: Zewei Zhou , Seth Z. Zhao , Tianhui Cai , Zhiyu Huang , Bolei Zhou , Jiaqi Ma<br>Score: 6<br>Reason: 멀티에이전트 시공간 프리트레인과 균형적 멀티태스크 학습은 멀티-뷰·다중 에이전트 perception/prediction 시스템 설계에 유용합니다.